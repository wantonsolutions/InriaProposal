\section{Intro}
\label{sec:intro}

Building large scale distributed systems is challenging. Rather than face the
headaches of coordinating thousands of machines by hands, developers use
frameworks which hide the
complexity~\cite{Dean:2008:MSD:1327452.1327492,Zaharia:2012:RDD:2228298.2228301,Murray_naiad:a}.
These frameworks sacrifice performance for generality and
simplicity~\cite{McSherry:2015:SBC:2831090.2831104}. Recent work has
demonstrated that some tasks benefit greatly from the implementation of custom
stateful algorithms~\cite{201559}. Such performance gains are not feasible for
the majority of developers, as the difficulty of checking the correctness of
their systems remains high.

Static and dynamic analysis are common approaches for building correct
distributed systems. Languages such as TLA+ and
COQ~\cite{specifying-and-verifying-systems-with-tla,
Corbineau:2007:DLC:1786134.1786139} are usefully for specifying systems, and
use model checkers to ensure that safety and liveness properties are not
violated. These checkers require extreme amounts of computation to verify and
require the maintenance of a fully flushed out specification, in addition to a
complete implementation. Further, the gap between specification, and
implementation admits bugs. Dynamic model checking techniques check
implementations by systematically exercising a system, or replaying known
faults~\cite{scottminimizing,yang_modist_nsdi09}. While these approaches are
less costly computationally, they represent a strict under approximation of the
systems behavior.

In this work we propose a dynamic analysis technique which simulates executions
using logs to reach safety violating states not reached during execution. Our
technique uses the logs generated from many executions of a system and composes
an aggregate state machine of a single \emph{super} process, which summarizes
all logged behavior. A runtime environment replicates these machines, and
systematically steps through state transitions. User specified safety and
liveness conditions are checked during simulation. Violations, and their
corresponding simulated traces are output to the user.

Our state machine aggregation algorithm builds on one fundamental observation -
If the logged state of any two processes match exactly, then their states are
the same. Our state machines are built by finding all occurrences of matching
state from all processes on all executions. The same matching rule is applied
to messages, and local events which trigger state transitions. Using exact
state matching, distributed states not reached during execution can be observed
through simulation, further all violations are real bugs.

Our exact state matching algorithm is the extension of theoretical
literature~\cite{Garg:2014:MAS:2580115.2580404}. While correct, their
\textbf{State Matching} conditions are rarely met in practice, for instance
\emph{ip: port} combinations alone fragment an aggregate state machine into a
sparse graph closely resembling traces themselves. To apply our analysis in
practice we extend our notion of exact state matching to relaxed state
matching, where the logged states of processes represent the same state in our
model if a subset of their states match. This relaxation of state matching
collapses the size of a state machine, but over aproximates state transitions,
thereby permitting false positives.

We propose an additional analysis procedure to order violations detected using
relaxed state matching, by their likelihood to be real violations. Prior to
simulation data invariants are collected, for each FSM node, from state traces
on variables which do not match. Operations which define transitions between
nodes on non matching variables are approximated using program synthesis.
Operations are synthesized using state transitions as input output examples as
inputs to the popular Z3 SMT solver.  During simulation non matching variables
are approximated by applying operations generated by the synthesis. False
positive likelyhood is evaluated by checking invariant violations generated by
the simulated execution. Traces which violate the minimal number of invariants
are reported to the user, as they are least likely to have diverged from the
systems constrained behavior.

The rest of the paper is arranged as follows. Section~\ref{sec:model} Defines
our model of a distributed system, and FSM construction.
Section~\ref{sec:system} describes our system. Sections
~\ref{sec:evaluation} \& \ref{sec:timeline} outline a proposed evaluation, and
timeline.
